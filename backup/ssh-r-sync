#!/usr/bin/env python3

import itertools as it, operator as op, functools as ft
import os, sys, logging, contextlib, collections, subprocess, socket, pwd
import hashlib, math, json, base64, signal, time
import tempfile, pathlib as pl


p_fmt = lambda fmt,*a,**k: (
	[fmt.format(*a,**k)] if isinstance(fmt, str) else [[fmt, *a], k] )
p = lambda fmt,*a,**k: print(*p_fmt(fmt,*a,**k), file=sys.stderr, flush=True)

err_fmt = lambda err: '[{}] {}'.format(err.__class__.__name__, err)

class LogMessage:
	def __init__(self, fmt, a, k): self.fmt, self.a, self.k = fmt, a, k
	def __str__(self): return self.fmt.format(*self.a, **self.k) if self.a or self.k else self.fmt

class LogStyleAdapter(logging.LoggerAdapter):
	def __init__(self, logger, extra=None):
		super(LogStyleAdapter, self).__init__(logger, extra or {})
	def log(self, level, msg, *args, **kws):
		if not self.isEnabledFor(level): return
		log_kws = {} if 'exc_info' not in kws else dict(exc_info=kws.pop('exc_info'))
		msg, kws = self.process(msg, kws)
		self.logger._log(level, LogMessage(msg, args, kws), (), **log_kws)

get_logger = lambda name: LogStyleAdapter(logging.getLogger(name))
log = get_logger('main')


class SSHRsyncConfig:
	# recv_port_* settings should be same on server/client
	recv_port_range = 6000, 6999
	recv_port_retries = 4
	recv_port_hash_key = b'J\xbc\xed\xa3\xa5\x02E(\xde\xdc#h\xa4\xa5\xa4t'

	hs_hello = b'ssh-r-sync o/ 1'
	hs_timeout = 5.0
	hs_key_size = 64

	ssh_opts = '''
		-oControlPath=none -oControlMaster=no
		-oConnectTimeout=180 -oServerAliveInterval=6 -oServerAliveCountMax=10
		-oBatchMode=yes -oPasswordAuthentication=no -oNumberOfPasswordPrompts=0
		-oExitOnForwardFailure=yes -T'''.split()

class SSHRsyncError(Exception):
	def __init__(self, *args):
		super().__init__(str(p_fmt(*args)[0]))


def str_part(s, sep, default=None):
	'Examples: str_part("user@host", "<@", "root"), str_part("host:port", ":>")'
	c = sep.strip('<>')
	if sep.strip(c) == '<': return (default, s) if c not in s else s.split(c, 1)
	else: return (s, default) if c not in s else s.rsplit(c, 1)

b64_str = lambda v: base64.urlsafe_b64encode(v).decode()
b64_bytes = lambda v: base64.urlsafe_b64decode(v.encode())

def hash_to_int(name, retry, n_max, **blake2_kws):
	'Returns integer hash within n_max range from name/retry values.'
	assert n_max > 0, n_max
	n_bits = math.ceil(math.log(n_max + 1, 2))
	n_bytes = math.ceil(n_bits / 8)
	mac = retry.to_bytes(1, 'big') + name.encode()
	for n in range(1000):
		mac = hashlib.blake2b(mac, **blake2_kws).digest()
		for o in range(0, 8//n_bytes):
			n = int.from_bytes(mac[o*n_bytes:(o+1)*n_bytes], 'big')
			if n_bits % 8: n >>= 8 - n_bits % 8
			if n <= n_max: return n # (n % n_max) would add bias for small values
	raise ValueError('Failed to get int within range after many hashes')

@contextlib.contextmanager
def err_timeout(timeout, err_t, *err_args):
	def timeout_handler(sig, frm): raise err_t(*err_args)
	handler_prev = signal.signal(signal.SIGALRM, timeout_handler)
	delay, interval = signal.setitimer(signal.ITIMER_REAL, timeout)
	assert not delay or interval
	try: yield
	finally:
		signal.setitimer(signal.ITIMER_REAL, 0)
		if handler_prev: signal.signal(signal.SIGALRM, handler_prev)

def proc_close(proc, wait=1, wait_base=0.3):
	if not proc or proc.poll() is not None: return
	close_ops = [proc.terminate, proc.kill]
	if proc.stdin: close_ops = [proc.stdin.close] + close_ops
	if isinstance(wait, (int, float)) and wait > 0:
		wait = list(n*wait for n, func in enumerate(close_ops, 1))
	wait = dict(enumerate(wait or list()))
	for n, func in enumerate(close_ops):
		with contextlib.suppress(OSError): func()
		with contextlib.suppress(subprocess.TimeoutExpired):
			proc.wait(wait.get(n, wait_base))
			break

def temp_file(prefix, contents=None):
	tmp = tempfile.NamedTemporaryFile('w', prefix=prefix)
	try:
		if contents:
			tmp.write(contents)
			tmp.flush()
	except:
		tmp.close()
		raise
	return tmp


SSHPipe = collections.namedtuple('SSHPipe', 'send recv')
RsyncInfo = collections.namedtuple('RsyncInfo', 'user key mod su')

def create_ssh_tunnel(ctx, conf, dst, port, name, rsync_info):
	hs_timeout_ctx = ft.partial( err_timeout,
		conf.hs_timeout, SSHRsyncError, 'Timeout waiting for receiver' )

	sock = ctx.enter_context(
		socket.socket(socket.AF_INET, socket.SOCK_STREAM) )
	sock.bind(('localhost', 0)) # to get os-picked open port to tunnel to
	addr, rsync_port = sock.getsockname()
	sock.listen(1)

	for attempt in range(conf.recv_port_retries+1):
		tun_port = conf.recv_port_range[0] + hash_to_int( name, attempt,
			conf.recv_port_range[1] - conf.recv_port_range[0], key=conf.recv_port_hash_key )
		ssh = subprocess.Popen(
			[ 'ssh', *(conf.ssh_opts or list()),
				'-R', f'{tun_port}:localhost:{rsync_port}', *([f'-p{port}'] if port else []), dst ],
			stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=sys.stderr )
		ssh_recv = open(ssh.stdout.fileno(), 'rb', 0)
		ssh_send = open(ssh.stdin.fileno(), 'wb', 0)
		with hs_timeout_ctx(): hello = ssh_recv.readline().rstrip(b'\n')
		if hello:
			ctx.callback(proc_close, ssh)
			ssh = None
			break
		log.debug( 'No "hello" from the other side,'
			' assuming tunnel failure (attempt={})', attempt+1 )
	else: raise SSHRsyncError('SSH connection failed')
	if hello != conf.hs_hello:
		raise SSHRsyncError( 'Hello-string mismatch:'
			' local={!r} remote={!r}', conf.hs_hello, hello )

	key = os.urandom(conf.hs_key_size)
	info = dict( name=name, port=tun_port,
		key=b64_str(key), rsync=rsync_info._asdict() )

	with hs_timeout_ctx():
		ssh_send.write(conf.hs_hello + b'\n')
		ssh_send.write(json.dumps(info).encode() + b'\n')

	key_recv = hashlib.blake2b(key, person=b'server', key=conf.hs_hello).digest()
	key_push = hashlib.blake2b(key, person=b'client', key=conf.hs_hello).digest()
	assert len(key_recv) == len(key_push) == conf.hs_key_size, [len(key_recv), len(key_push)]

	sock.settimeout(conf.hs_timeout)
	sock_conn, sock_addr = sock.accept()
	ctx.callback(sock_conn.close)
	sock_conn.settimeout(conf.hs_timeout)
	sock_conn.send(key_push)
	key = sock_conn.recv(conf.hs_key_size)
	if len(key) != conf.hs_key_size or key != key_recv:
		raise SSHRsyncError('ssh/socket mismatch (len={}/{})', len(key), conf.hs_key_size)

	sock_conn.close()
	sock.close()

	return rsync_port, SSHPipe(ssh_send, ssh_recv)

def create_rsync_conf( ctx, path, rsync_info,
		filter_file=None, filter_dir_file=None, debug=False ):
	if filter_file or filter_dir_file:
		rsync_filter = ctx.enter_context(
			tempfile.NamedTemporaryFile('w', prefix='.ssh-r-sync.filter.') )
		if filter_dir_file: rsync_filter.write(f'merge-dir {filter_dir_file}\n')
		if filter_file: rsync_filter.write(pl.Path(filter_file).read_text())
		rsync_filter.flush()
	else: rsync_filter = None
	rsync_secrets = ctx.enter_context(
		temp_file('.ssh-r-sync.passwd.', f'{rsync_info.user}:{rsync_info.key}\n') )
	rsync_lock = ctx.enter_context(temp_file('.ssh-r-sync.lock.'))
	rsync_conf = [
		'hosts allow = localhost', 'read only = true', 'numeric ids = true',
		'use chroot = {}'.format('no' if not rsync_info.su else 'yes'),
		'max connections = 1', f'lock file = {rsync_lock.name}',
		f'secrets file = {rsync_secrets.name}', f'auth users = {rsync_info.user}' ]
	if debug: rsync_conf.append('log file = /dev/stderr')
	path = pl.Path(path).resolve()
	rsync_conf.extend([f'[{rsync_info.mod}]', f' path = {path}'])
	if rsync_filter: rsync_conf.append(f' filter = merge {rsync_filter.name}')
	rsync_conf = ctx.enter_context(
		temp_file('.ssh-r-sync.conf.', '\n'.join(rsync_conf + [''])) )
	return rsync_conf.name


def main(args=None):
	conf = SSHRsyncConfig()

	import argparse, textwrap

	dedent = lambda text: (textwrap.dedent(text).strip('\n') + '\n').replace('\t', '  ')
	class SmartHelpFormatter(argparse.HelpFormatter):
		def __init__(self, *args, **kws):
			return super().__init__(*args, **kws, width=100)
		def _fill_text(self, text, width, indent):
			if '\n' not in text: return super()._fill_text(text, width, indent)
			return ''.join( indent + line
				for line in text.replace('\t', '  ').splitlines(keepends=True) )
		def _split_lines(self, text, width):
			return super()._split_lines(text, width)\
				if '\n' not in text else dedent(text).splitlines()

	parser = argparse.ArgumentParser(
		formatter_class=SmartHelpFormatter,
		usage='%(prog)s [options] [user@]host[:port]',
		description=dedent('''
			"ssh -R rsync" script to backup stuff via ssh/rsync.
			It works by ssh'ing into remote backup server, requesting it to make a backup,
				which then happens over same ssh connection, using reverse-tunnel opened there.
			ssh console channel is used to send backup parameters.

			This avoids following problematic things:
			- Pushing stuff to remote, which can be exploited to delete things.
			- Using insecure network channels and/or rsync auth - ssh only.
			- Having any kind of insecure auth or port open on backup server - ssh only.
			- Requiring backed-up machine to be accessible on the net for backup-pulls.

			On the backup-server side, only one
				locked-down single-command ssh account is necessary.

			To get rsync with full fs access, use -r/--rsync option and binary with
				cap_dac_read_search (read) / cap_dac_override (write) posix capabilities.
			Idea is to for backup process to be as simple as ssh'ing into remote host.'''))

	group = parser.add_argument_group('Basic required arguments')
	group.add_argument('host', metavar='[user@]host[:port]',
		help='''
			Destination [user@]host[:port] spec for ssh command.
			If "user" part is omitted, current local user name will be added.''')
	group.add_argument('path', help='Local path to backup.')

	group = parser.add_argument_group('Rsync/backup options')
	group.add_argument('-r', '--rsync', metavar='path',
		help='''
			Path to custom rsync binary, e.g. one with all necessary posix caps enabled.
			If specified, elevated privileges for rsync are assumed, and parameters like -HaAX are used.
			Passing -u/--rsync-user option allows to disable this
				behavior and only copy stuff that regular users can access.''')
	group.add_argument('-u', '--rsync-user', action='store_true',
		help='Don not assume elevated privileges when -r/--rsync path is specified.')
	group.add_argument('-n', '--name', metavar='name',
		help='Local machine name, which is used for backup'
			' cleanup and deduplication. Picked as uname.nodename, if not specified.')
	group.add_argument('-f', '--filter-file', metavar='path',
		help='Local file to use as rsync daemon filter rules,'
			' to be passed as "filter = merge <file>" in its config.')
	group.add_argument('-x', '--filter-dir-file', metavar='name',
		help='Simplified form of -f/--filter-file,'
				' adding "dir-merge <name>" to rsync filter rule.'
			' Same as using one-liner --filter-file with that directive.')

	group = parser.add_argument_group('SSH options')
	group.add_argument('-p', '--port', metavar='port',
		help='Alternative way to specify port, similar to ssh binary.')
	group.add_argument('--no-ssh-opts', action='store_true',
		help='''
			Do not pass any advanced -o<stuff> ssh options which script does by default.
			ssh will still read stuff from ~/.ssh/config, so any new ones can be specified there.
			Default options are:\n{}'''.format('\n'.join(textwrap.wrap(
				' '.join(conf.ssh_opts), width=90, initial_indent='\t'*4, subsequent_indent='\t'*4 ))))

	group = parser.add_argument_group('Misc options')
	group.add_argument('-d', '--debug', action='store_true', help='Verbose operation mode.')
	opts = parser.parse_args(sys.argv[1:] if args is None else args)

	logging.basicConfig(level=logging.DEBUG if opts.debug else logging.WARNING)

	ssh_dst, ssh_port = str_part(opts.host, ':>')
	name = opts.name or os.uname().nodename
	if opts.no_ssh_opts: conf.ssh_opts.clear()

	with contextlib.ExitStack() as ctx:
		rsync_info = RsyncInfo( key=b64_str(os.urandom(6)),
			user='sshrsync', mod='sshrsync', su=opts.rsync and not opts.rsync_user )
		rsync_conf_path = create_rsync_conf( ctx, opts.path, rsync_info,
			filter_file=opts.filter_file, filter_dir_file=opts.filter_dir_file, debug=opts.debug )
		rsync_port, ssh = create_ssh_tunnel(ctx, conf, ssh_dst, ssh_port, name, rsync_info)
		rsync = subprocess.Popen([
			pl.Path(opts.rsync).resolve() if opts.rsync else 'rsync',
			'--daemon', '--no-detach', f'--port={rsync_port}', f'--config={rsync_conf_path}' ])
		ssh.send.write(b'start\n')
		ack = ssh.recv.readline().rstrip(b'\n')
		if ack != b'done': raise SSHRsyncError('Invalid/missing backup completion ack: {!r}', ack)

if __name__ == '__main__': sys.exit(main())
